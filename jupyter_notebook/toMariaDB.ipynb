{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.884 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 前往父目錄\n",
    "os.chdir(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"),\n",
    "                             os.path.pardir)))\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "import copy\n",
    "## 載入自訂字典\n",
    "jieba.load_userdict(\"./keyWordsDB/AllKeyWords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyWordsComparator:\n",
    "    def __read_key_words(self, path):\n",
    "        key_words_list = []\n",
    "        with open(path, \"r\", encoding=\"utf8\") as r:\n",
    "            for item in r.readlines():\n",
    "                key_words_list.append(item.replace(\"\\ufeff\", \"\").strip())\n",
    "        return key_words_list\n",
    "\n",
    "    # 取得一文字檔的原始文章\n",
    "    def __txt_raw_text(self):\n",
    "        with open(os.path.join(self.txt_path, self.txt_file_name), \"r\", encoding=\"cp950\") as txt_reader:\n",
    "            text = txt_reader.read()\n",
    "            text = text.replace(\"\\n\", \"\").replace(\"\\u3000\", \"\\n\")\n",
    "        return text\n",
    "\n",
    "    def __init__(self, txt_path, txt_file_name):\n",
    "        # 讀取 Round1, Round2_1 ~ Round2_4,  Round3_1 ~ Round3_4 KeysWords\n",
    "        self.Round1 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round1.txt\")\n",
    "        self.Round2_1 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round2_1.txt\")\n",
    "        self.Round2_2 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round2_2.txt\")\n",
    "        self.Round2_3 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round2_3.txt\")\n",
    "        self.Round2_4 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round2_4.txt\")\n",
    "        self.Round3_1 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round3_1.txt\")\n",
    "        self.Round3_2 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round3_2.txt\")\n",
    "        self.Round3_3 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round3_3.txt\")\n",
    "        self.Round3_4 = self.__read_key_words(\"./KeyWordsDB/Poisoning KeyWords/Round3_4.txt\")\n",
    "\n",
    "        self.txt_path = txt_path\n",
    "        self.txt_file_name = txt_file_name\n",
    "        self.txt_content = self.__txt_raw_text()\n",
    "        self.segs = self.__get_content_segs()\n",
    "\n",
    "    def __get_content_segs(self):\n",
    "        return jieba.lcut(self.txt_content.strip())\n",
    "\n",
    "    def Main_seg_and_stastic(self, df_mode = True):\n",
    "        \"\"\"\n",
    "        變數宣告區\n",
    "        \"\"\"\n",
    "        ##\n",
    "        # 共用變數\n",
    "        Marked_text = copy.deepcopy(self.txt_content)\n",
    "        Marked_segs = copy.deepcopy(self.segs)\n",
    "\n",
    "        # R1 variable\n",
    "        R1_count_array = np.zeros(len(self.Round1))\n",
    "        R1_keyW_list = []\n",
    "        R1_count = 0\n",
    "        R1_tf = 0\n",
    "\n",
    "        # R21 variable\n",
    "        R21_count_array = np.zeros(len(self.Round2_1))\n",
    "        R21_keyW_list = []\n",
    "        R21_count = 0\n",
    "        R21_tf = 0\n",
    "\n",
    "        # R22 variable\n",
    "        R22_count_array = np.zeros(len(self.Round2_2))\n",
    "        R22_keyW_list = []\n",
    "        R22_count = 0\n",
    "        R22_tf = 0\n",
    "\n",
    "        # R23 variable\n",
    "        R23_count_array = np.zeros(len(self.Round2_3))\n",
    "        R23_keyW_list = []\n",
    "        R23_count = 0\n",
    "        R23_tf = 0\n",
    "\n",
    "        # R24 variable\n",
    "        R24_count_array = np.zeros(len(self.Round2_4))\n",
    "        R24_keyW_list = []\n",
    "        R24_count = 0\n",
    "        R24_tf = 0\n",
    "\n",
    "        # R31 variable\n",
    "        R31_count_array = np.zeros(len(self.Round3_1))\n",
    "        R31_keyW_list = []\n",
    "        R31_count = 0\n",
    "        R31_tf = 0\n",
    "\n",
    "        # R32 variable\n",
    "        R32_count_array = np.zeros(len(self.Round3_2))\n",
    "        R32_keyW_list = []\n",
    "        R32_count = 0\n",
    "        R32_tf = 0\n",
    "\n",
    "        # R33 variable\n",
    "        R33_count_array = np.zeros(len(self.Round3_3))\n",
    "        R33_keyW_list = []\n",
    "        R33_count = 0\n",
    "        R33_tf = 0\n",
    "\n",
    "        # R34 variable\n",
    "        R34_count_array = np.zeros(len(self.Round3_4))\n",
    "        R34_keyW_list = []\n",
    "        R34_count = 0\n",
    "        R34_tf = 0\n",
    "\n",
    "        for seg in self.segs:\n",
    "            \"\"\"\n",
    "            處理Round 1 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round1:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R1_count_array[self.Round1.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R1>\" + seg + \"</R1>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R1>\" + seg + \"</R1>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R1>\" + seg + \"</R1>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R1_keyW_list\n",
    "                if not (seg in R1_keyW_list):\n",
    "                    R1_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 21 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round2_1:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R21_count_array[self.Round2_1.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R21>\" + seg + \"</R21>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R21>\" + seg + \"</R21>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R21>\" + seg + \"</R21>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R21_keyW_list\n",
    "                if not (seg in R21_keyW_list):\n",
    "                    R21_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 22 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round2_2:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R22_count_array[self.Round2_2.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R22>\" + seg + \"</R22>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R22>\" + seg + \"</R22>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R22>\" + seg + \"</R22>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R22_keyW_listhttp://localhost:8888/notebooks/%E7%81%BD%E5%AE%B3%E4%BA%8B%E6%95%85%E5%B0%88%E6%A1%88/%E7%AC%AC%E4%BA%8C%E7%89%88-%E6%96%B0%E8%81%9E%E6%96%B7%E8%A9%9E%E7%AF%A9%E9%81%B8%E7%B3%BB%E7%B5%B1-0407.ipynb#\n",
    "                if not (seg in R22_keyW_list):\n",
    "                    R22_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 23 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round2_3:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R23_count_array[self.Round2_3.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R23>\" + seg + \"</R23>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R23>\" + seg + \"</R23>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R23>\" + seg + \"</R23>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R23_keyW_list\n",
    "                if not (seg in R23_keyW_list):\n",
    "                    R23_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 24 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round2_4:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R24_count_array[self.Round2_4.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R24>\" + seg + \"</R24>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R24>\" + seg + \"</R24>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R24>\" + seg + \"</R24>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R24_keyW_list\n",
    "                if not (seg in R24_keyW_list):\n",
    "                    R24_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 31 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round3_1:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R31_count_array[self.Round3_1.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R31>\" + seg + \"</R31>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R31>\" + seg + \"</R31>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R31>\" + seg + \"</R31>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R31_keyW_list\n",
    "                if not (seg in R31_keyW_list):\n",
    "                    R31_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 32 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round3_2:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R32_count_array[self.Round3_2.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R32>\" + seg + \"</R32>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R32>\" + seg + \"</R32>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R32>\" + seg + \"</R32>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R32_keyW_list\n",
    "                if not (seg in R32_keyW_list):\n",
    "                    R32_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 33 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round3_3:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R33_count_array[self.Round3_3.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R33>\" + seg + \"</R33>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R33>\" + seg + \"</R33>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R33>\" + seg + \"</R33>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R33_keyW_list\n",
    "                if not (seg in R33_keyW_list):\n",
    "                    R33_keyW_list.append(seg)\n",
    "            \"\"\"\n",
    "            處理Round 34 狀況\n",
    "            \"\"\"\n",
    "            if seg in self.Round3_4:\n",
    "                # 出現特徵詞的地方+1\n",
    "                R34_count_array[self.Round3_4.index(seg)] += 1\n",
    "                # 出現特徵詞的地方，在原文Mark\n",
    "                if not (\"<R34>\" + seg + \"</R34>\" in Marked_text):\n",
    "                    Marked_text = Marked_text.replace(seg, \"<R34>\" + seg + \"</R34>\")\n",
    "                # 出現特徵詞的地方，在斷詞的list Mark\n",
    "                try:\n",
    "                    Marked_segs[Marked_segs.index(seg)] = \"<R34>\" + seg + \"</R34>\"\n",
    "                except ValueError:\n",
    "                    # print(\"ValueError\")\n",
    "                    pass\n",
    "                # 出現的特徵詞放入 R34_keyW_list\n",
    "                if not (seg in R34_keyW_list):\n",
    "                    R34_keyW_list.append(seg)\n",
    "\n",
    "            \"\"\"\n",
    "            共同變數區\n",
    "            \"\"\"\n",
    "\n",
    "            ### 在Round1 特徵詞出現的種類\n",
    "            R1_count = sum(R1_count_array != 0)\n",
    "            # 在Round1 特徵詞出現的詞頻\n",
    "            R1_tf = sum(R1_count_array)\n",
    "            \"\"\"\n",
    "            R2\n",
    "            \"\"\"\n",
    "            ### 在Round21 特徵詞出現的種類\n",
    "            R21_count = sum(R21_count_array != 0)\n",
    "            # 在Round21 特徵詞出現的詞頻\n",
    "            R21_tf = sum(R21_count_array)\n",
    "            ### 在Round22 特徵詞出現的種類\n",
    "            R22_count = sum(R22_count_array != 0)\n",
    "            # 在Round22 特徵詞出現的詞頻\n",
    "            R22_tf = sum(R22_count_array)\n",
    "            ### 在Round23 特徵詞出現的種類\n",
    "            R23_count = sum(R23_count_array != 0)\n",
    "            # 在Round23 特徵詞出現的詞頻\n",
    "            R23_tf = sum(R23_count_array)\n",
    "            ### 在Round24 特徵詞出現的種類\n",
    "            R24_count = sum(R24_count_array != 0)\n",
    "            # 在Round24 特徵詞出現的詞頻\n",
    "            R24_tf = sum(R24_count_array)\n",
    "            \"\"\"\n",
    "            R3\n",
    "            \"\"\"\n",
    "            ### 在Round31 特徵詞出現的種類\n",
    "            R31_count = sum(R31_count_array != 0)\n",
    "            # 在Round31 特徵詞出現的詞頻\n",
    "            R31_tf = sum(R31_count_array)\n",
    "            ### 在Round32 特徵詞出現的種類\n",
    "            R32_count = sum(R32_count_array != 0)\n",
    "            # 在Round32 特徵詞出現的詞頻\n",
    "            R32_tf = sum(R32_count_array)\n",
    "            ### 在Round33 特徵詞出現的種類\n",
    "            R33_count = sum(R33_count_array != 0)\n",
    "            # 在Round33 特徵詞出現的詞頻\n",
    "            R33_tf = sum(R33_count_array)\n",
    "            ### 在Round34 特徵詞出現的種類\n",
    "            R34_count = sum(R34_count_array != 0)\n",
    "            # 在Round34 特徵詞出現的詞頻\n",
    "            R34_tf = sum(R34_count_array)\n",
    "\n",
    "        if df_mode :\n",
    "            return pd.DataFrame([[self.txt_file_name, R1_count_array, R1_keyW_list, R1_count, R1_tf, \\\n",
    "                       R21_count_array, R21_keyW_list, R21_count, R21_tf, \\\n",
    "                       R22_count_array, R22_keyW_list, R22_count, R22_tf, \\\n",
    "                       R23_count_array, R23_keyW_list, R23_count, R23_tf, \\\n",
    "                       R24_count_array, R24_keyW_list, R24_count, R24_tf, \\\n",
    "                       R31_count_array, R31_keyW_list, R31_count, R31_tf, \\\n",
    "                       R32_count_array, R32_keyW_list, R32_count, R32_tf, \\\n",
    "                       R33_count_array, R33_keyW_list, R33_count, R33_tf, \\\n",
    "                       R34_count_array, R34_keyW_list, R34_count, R34_tf, \\\n",
    "                       Marked_text, Marked_segs, len(self.segs)]], columns=[\"txt_file_name\", \"R1_count_array\", \"R1_keyW_list\", \"R1_count\", \"R1_tf\",\n",
    "                                                \"R21_count_array\", \"R21_keyW_list\", \"R21_count\", \"R21_tf\",\n",
    "                                                \"R22_count_array\", \"R22_keyW_list\", \"R22_count\", \"R22_tf\",\n",
    "                                                \"R23_count_array\", \"R23_keyW_list\", \"R23_count\", \"R23_tf\",\n",
    "                                                \"R24_count_array\", \"R24_keyW_list\", \"R24_count\", \"R24_tf\",\n",
    "                                                \"R31_count_array\", \"R31_keyW_list\", \"R31_count\", \"R31_tf\",\n",
    "                                                \"R32_count_array\", \"R32_keyW_list\", \"R32_count\", \"R32_tf\",\n",
    "                                                \"R33_count_array\", \"R33_keyW_list\", \"R33_count\", \"R33_tf\",\n",
    "                                                \"R34_count_array\", \"R34_keyW_list\", \"R34_count\", \"R34_tf\",\n",
    "                                                \"Marked_text\", \"Marked_segs\", \"seg_number\"])\n",
    "        else:\n",
    "            return [self.txt_file_name, R1_count_array, R1_keyW_list, R1_count, R1_tf, \\\n",
    "                       R21_count_array, R21_keyW_list, R21_count, R21_tf, \\\n",
    "                       R22_count_array, R22_keyW_list, R22_count, R22_tf, \\\n",
    "                       R23_count_array, R23_keyW_list, R23_count, R23_tf, \\\n",
    "                       R24_count_array, R24_keyW_list, R24_count, R24_tf, \\\n",
    "                       R31_count_array, R31_keyW_list, R31_count, R31_tf, \\\n",
    "                       R32_count_array, R32_keyW_list, R32_count, R32_tf, \\\n",
    "                       R33_count_array, R33_keyW_list, R33_count, R33_tf, \\\n",
    "                       R34_count_array, R34_keyW_list, R34_count, R34_tf, \\\n",
    "                       Marked_text, Marked_segs, len(self.segs)], \\\n",
    "                     [\"txt_file_name\", \"R1_count_array\", \"R1_keyW_list\", \"R1_count\", \"R1_tf\",\n",
    "                                                \"R21_count_array\", \"R21_keyW_list\", \"R21_count\", \"R21_tf\",\n",
    "                                                \"R22_count_array\", \"R22_keyW_list\", \"R22_count\", \"R22_tf\",\n",
    "                                                \"R23_count_array\", \"R23_keyW_list\", \"R23_count\", \"R23_tf\",\n",
    "                                                \"R24_count_array\", \"R24_keyW_list\", \"R24_count\", \"R24_tf\",\n",
    "                                                \"R31_count_array\", \"R31_keyW_list\", \"R31_count\", \"R31_tf\",\n",
    "                                                \"R32_count_array\", \"R32_keyW_list\", \"R32_count\", \"R32_tf\",\n",
    "                                                \"R33_count_array\", \"R33_keyW_list\", \"R33_count\", \"R33_tf\",\n",
    "                                                \"R34_count_array\", \"R34_keyW_list\", \"R34_count\", \"R34_tf\",\n",
    "                                                \"Marked_text\", \"Marked_segs\", \"seg_number\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59min 10s, sys: 5.13 s, total: 59min 16s   \n",
      "Wall time: 59min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "news_dir_path = \"/home/jam/桌面/魏老計畫/news_db/output/事故\"\n",
    "stastic_list = []\n",
    "for idx, file in enumerate(os.listdir(news_dir_path)):\n",
    "    news_path = os.path.join(news_dir_path, file)\n",
    "    Comparator = KeyWordsComparator(txt_path=news_dir_path,\n",
    "                                                   txt_file_name=file)\n",
    "    stastic_data, colname = Comparator.Main_seg_and_stastic(df_mode = False)\n",
    "    print(\"\\r %.2f  %s                    \"%(((idx + 1)/len(os.listdir(news_dir_path)))*100, file), end=\"\\r\", flush=True)\n",
    "    stastic_list.append(stastic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stastic_result = pd.DataFrame(stastic_list, columns=colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stastic_result[['txt_file_name', 'R1_count', 'R1_tf',\n",
    "        'R21_count', 'R21_tf',\n",
    "        'R22_count', 'R22_tf',\n",
    "        'R23_count', 'R23_tf',\n",
    "        'R24_count', 'R24_tf',\n",
    "        'R31_count', 'R31_tf',\n",
    "        'R32_count', 'R32_tf',\n",
    "        'R33_count', 'R33_tf',\n",
    "        'R34_count', 'R34_tf',\n",
    "       'Marked_text', 'Marked_segs', 'seg_number']].to_excel(\"stastic_result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data = stastic_result[['txt_file_name', 'R1_count', 'R1_tf',\n",
    "        'R21_count', 'R21_tf',\n",
    "        'R22_count', 'R22_tf',\n",
    "        'R23_count', 'R23_tf',\n",
    "        'R24_count', 'R24_tf',\n",
    "        'R31_count', 'R31_tf',\n",
    "        'R32_count', 'R32_tf',\n",
    "        'R33_count', 'R33_tf',\n",
    "        'R34_count', 'R34_tf',\n",
    "       'Marked_text', 'Marked_segs', 'seg_number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accident_stastic =  filter_data.sort_values(by=[\"R1_count\", \"R21_count\", \"R22_count\"], ascending=False)\n",
    "## data clean\n",
    "accident_stastic[[\"txt_file_name\", \"Marked_text\", \"Marked_segs\"]] = \\\n",
    "accident_stastic[[\"txt_file_name\", \"Marked_text\", \"Marked_segs\"]].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_db_name = \"Chemicalsdb\"\n",
    "engine = create_engine(r\"mysql+mysqldb://root:root@127.0.0.1:3307/\"+SQL_db_name+\"?charset=utf8\")\n",
    "connection = engine.connect()\n",
    "\n",
    "accident_stastic.to_sql(\"accident_stastic\", con=connection, if_exists=\"replace\")\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
